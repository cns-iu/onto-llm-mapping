# Set F-score beta
beta = 2
# Evaluates mapped concepts, hit-miss stats, precision, recall, f-score, & MRR for LLM mapping results.
# Loop through each data file to calculate top line stats, hit-miss rates,
# f-scores, mrr and mac scores for each set of prepared model results.
i=1
for(i in 1:length(llm_mapping_paths)){
# Load data
data <- read.csv(file=llm_mapping_paths[i],
header = T, encoding = "UFT-8")
# Identify project model
model <- unique(data$model)
# Top line evaluation - subject concepts with and without mapping results (skipped).
results_subject_concepts_mapped <-
data %>%
filter(model_analyzed==TRUE) %>%
select(model,subject_id) %>%
distinct() %>%
ddply(.(model), summarise,
mappable_concepts = mappable_concepts,
mapped_concepts = length(subject_id),
skipped_concepts = mappable_concepts - length(subject_id),
mapped_concepts_percent = round(length(subject_id)/mappable_concepts, 3))
# Calculate hit and miss statistics for model results
results_hit_miss <-
data %>%
select(model, subject_id, hit_miss_concept) %>%
distinct() %>%
mutate(value=1) %>%
pivot_wider(id_cols = model,
names_from = hit_miss_concept,
values_from = value,
values_fn = length) %>%
mutate(hit_percent = round(Hit/mappable_concepts,2),
miss_percent = round(Miss/mappable_concepts,2)) %>%
select(model,Hit,Miss,hit_percent, miss_percent)
names(results_hit_miss)[2:3] <- c("hit","miss")
# Calculate hit and miss statistics for model results - Group level
results_hit_miss_groups <-
data %>%
select(model, subject_id, mesh_concept_group, hit_miss_concept) %>%
distinct() %>%
mutate(Value=1) %>%
pivot_wider(id_cols = model,
names_from = c(hit_miss_concept, mesh_concept_group),
values_from = Value,
values_fn = length) %>%
select(model,'Hit_Anatomical structure','Miss_Anatomical structure',
'Hit_Cell type', 'Miss_Cell type',)
names(results_hit_miss_groups)[2:5] <- c("hit_as","miss_as","hit_ct","miss_ct")
results_hit_miss_groups <-
results_hit_miss_groups %>%
mutate(hit_as_percent= round(hit_as/mappable_concepts_as,2),
miss_as_percent= round(miss_as/mappable_concepts_as,2),
hit_ct_percent= round(hit_ct/mappable_concepts_ct,2),
miss_ct_percent= round(miss_ct/mappable_concepts_ct,2))
# Precision at L
precision <-
data %>%
select(model, subject_id, accurate_mapping, concept_pair_rank) %>%
ddply(.(model, subject_id), summarise,
score_at_k = max(accurate_mapping),
precision_k = max(concept_pair_rank),
precision = max(accurate_mapping)/max(concept_pair_rank))
# Clean up precision for concepts llm skipped.
if(nrow(precision[is.na(precision$precision_k),])>0){
precision[is.na(precision$precision_k),]$precision_k <- 0
precision[is.na(precision$precision),]$precision <- 0
}
# Recall at L
recall <-
data %>%
select(model, subject_id, accurate_mapping, mapping_count) %>%
ddply(.(model, subject_id), summarise,
score_at_k = sum(accurate_mapping),
recall_k = max(mapping_count),
recall = sum(accurate_mapping)/max(mapping_count))
# Save model precision and recall calculations
mapping_scores_tmp <- join(precision, recall, by=c("model", "subject_id"))
write.csv(mapping_scores_tmp,
file=paste0(path_results_data,"/",model,
"-precision-recall-calculations.csv"),
row.names = FALSE)
# Mean Precision and Recall, calculate F-score at K
results_fscore <-
join(precision, recall, by=c("model", "subject_id")) %>%
select(model, precision, recall) %>%
ddply(.(model), summarise,
mean_precision = mean(precision, na.rm = T),
mean_recall = mean(recall, na.rm = T)) %>%
mutate(f_score=((1+beta^2)*mean_precision*mean_recall)/((beta^2*mean_precision)+mean_recall),
beta = beta)
rm(precision, recall, mapping_scores_tmp)
# Calculate Concept Level - Mean Reciprocal Rank (MRR)
# 1. Calculate reciprocal rank values for mapping records.
tmp0 <-
data %>%
mutate(reciprocal_rank = mapping_result_number/concept_pair_rank)
# 2. Calculate reciprocal rank for accurately mapped concepts.
tmp1 <-
tmp0 %>%
filter(mapping_result_number==1) %>%
select(model, subject_id, reciprocal_rank)
# 3. Calculate reciprocal rank for missed concepts.
tmp2 <-
tmp0 %>%
filter(hit_miss_concept=="Miss",
is.na(reciprocal_rank) == FALSE) %>%
ddply(.(model, subject_id), summarise,
reciprocal_rank = mean(reciprocal_rank, na.rm=TRUE))
# 4. Combine reciprocal rank calculations for each subject concept.
results_rr <-
union(tmp1,tmp2)
write.csv(results_rr,
file=paste0(path_results_data,"/",model,
"-concept-reciprocal-recall-calculations.csv"),
row.names = FALSE)
rm(tmp0, tmp1, tmp2)
# 5. Calculate mean reciprocal rank for the model
results_mrr <-
results_rr %>%
ddply(.(model), summarise,
mean_reciprocal_rank = mean(reciprocal_rank, na.rm=TRUE),
mean_reciprocal_rank_sd = sd(reciprocal_rank, na.rm=TRUE))
# Combine model evaluation statistics and organize variables.
evaluation_results_tmp <-
left_join(results_subject_concepts_mapped, results_hit_miss,
by="model") %>%
left_join(., results_hit_miss_groups, by="model") %>%
left_join(., results_fscore, by="model") %>%
left_join(., results_mrr, by="model") %>%
select(model, mappable_concepts, mapped_concepts,
skipped_concepts, mapped_concepts_percent,
hit, hit_as, hit_ct, miss, miss_as, miss_ct,
hit_percent, hit_as_percent, hit_ct_percent,
miss_percent, miss_as_percent, miss_ct_percent,
mean_precision, mean_recall, f_score, beta,
mean_reciprocal_rank, mean_reciprocal_rank_sd)
# Add model level statistics to data frame
evaluation_results <- rbind(evaluation_results, evaluation_results_tmp)
}
# save model evaluation results
write.csv(evaluation_results,
file=paste0(path_results_data,"/",project,
"-model-evaluation-results.csv"),
row.names = FALSE)
#### Set up environment ####
library(magrittr)
library(tidyr)
library(plyr)
library(dplyr)
library(stringr)
#### Load data ####
# Set Paths
# path_input_data <- paste0("./input-data/mesh-uberon-human/v0.0.1")
path_raw_data <- paste0("./raw-data/mesh-uberon-human/v0.0.1")
path_eval_data <- paste0("./validation/evaluation_mappings")
path_prep_data <- paste0("./validation/mesh-uberon-human/v0.0.1")
#Load in LLM mappings
# currently selects for vector results.
llm_mapping_paths <-
list.files(path=paste0(path_raw_data,"/mappings"),
pattern="vec.sssom.csv", full.names = TRUE)
#Load Ground Truth mapping Data
evaluative_mappings <-
read.csv(file=paste0(path_eval_data,"/concept-mapping-evaluation-lookup-table-MGINDA.csv"),
header = T, encoding = "UFT-8")
# identify mappable concepts from initial set of subject concepts)
mappable_concepts <-
evaluative_mappings[evaluative_mappings$mappability=="Mappable",]$subject_label %>%
unique()
llm_mapping_paths
#### Pre-process the data ####
for(i in 1:length(llm_mapping_paths)){
# Load LLM mapping results
data <- read.csv(file=llm_mapping_paths[i],
header = T, encoding = "UFT-8")
# grab project and model for data.
llm_result_file <- tail(unlist(str_split(llm_mapping_paths[i], pattern="\\/")),1)
llm_result_file <- str_split(llm_result_file, pattern="-vec")[[1]][1]
# extracting mapping tool info?
#mapping_tool
#mapping_tool_version
# Creates model and project label for data set.
data$model <- llm_result_file
# Creates concept pair id with concept labels.
data$pair_id <-
paste0(data$subject_id,"|",data$object_id)
# Re-order columns
data <- data[,c(9,8,1,3,4,10,2,5,6,7)]
# Subset to keep only results for mappable concepts
data <- data[data$subject_label %in% mappable_concepts,]
# Join 1: Evaluate mapping results using mapping evaluation look-up table.
data <- join(data, evaluative_mappings[,c(2,11)], by="pair_id")
# Set accuracy score for missing values, all to 0.
data[is.na(data$accurate_mapping),]$accurate_mapping <- 0
# Create concept_pair_rank values for subject concept mapping results.
data <-
data %>%
group_by(subject_id) %>%
mutate(concept_pair_rank = row_number()) %>%
ungroup()
#Identify any missing concepts, and return concept level labels and mapping stats
tmp <-
data[,c(1,3,7,11)] %>%
ddply(.(model, subject_id, subject_label),
summarise,
accurate_mapping=max(accurate_mapping, na.rm = TRUE)) %>%
mutate(model_analyzed = TRUE)
# Join 2: tmp concept level mapping results are joined to evaluation look up.
tmp <-
right_join(tmp,
unique(evaluative_mappings[
evaluative_mappings$mappability=="Mappable", c(3,4,8,12)]),
by=c("subject_id","subject_label")) %>%
fill(model, .direction="down")
# Updates missing values for absent subject concepts.
tmp[is.na(tmp$model_analyzed),]$model_analyzed <- FALSE
# Creates hit_miss_concept variable.
tmp$hit_miss_concept <- "Miss"
# Update hit_miss_concept variable.
tmp[tmp$accurate_mapping==1 & !is.na(tmp$accurate_mapping),]$hit_miss_concept <- "Hit"
# Reorder columns
tmp <- tmp[,c(1,2,3,5,8,6,4,7)]
# Join 3: Combine missing subject concepts back into results.
data <- left_join(tmp, data, by=c("model","subject_id","subject_label"))
# Reorder columns
data <- data[,c(1,9,2,10:12,3,13,6,14,16,17,8,5,4)]
# Update name of variable
names(data)[11] <- "accurate_mapping"
# Create hit_miss_mapping from hit_miss_concept
data$hit_miss_mapping <- data$hit_miss_concept
# Update values for hit_miss_mapping, where accurate mapping values are 0.
data[data$accurate_mapping==0 | is.na(data$accurate_mapping)==T ,]$hit_miss_mapping <- "Miss"
# Update mapping values for accurate_mapping for absent subject concepts variables.
data[is.na(data$accurate_mapping),]$accurate_mapping <- 0
# Pivot 2: Calculate mapping result number (most subject concepts have 1 valid result).
tmp2 <-
data[data$accurate_mapping==1,c("subject_id","pair_id","mapping_count")] %>%
group_by(subject_id) %>%
mutate(mapping_result_number = row_number()) %>%
ungroup() %>%
select(pair_id,mapping_result_number)
# Join 4
data <- join(data, tmp2, by="pair_id")
data[is.na(data$mapping_result_number)==T,]$mapping_result_number <- 0
# Reorder columns
data <- data[,c(1:13,17,14,16,15)]
# Export prepared results.
write.csv(data,file=paste0(path_prep_data,"/",llm_result_file,"-prepared.csv"), row.names =F )
# Clean up loop
rm(tmp, tmp2, llm_result_file)
}
rm(i, data, llm_mapping_paths, evaluative_mappings, mappable_concepts,
path_eval_data, path_prep_data, path_raw_data)
#### Set up environment ####
library(magrittr)
library(tidyr)
library(plyr)
library(dplyr)
#### Set Paths ####
# Paths
path_input_data <- paste0("./input-data/mesh-uberon-human/v0.0.1")
path_eval_data <- paste0("./validation/evaluation_mappings")
path_prep_data <- paste0("./validation/mesh-uberon-human/v0.0.1")
# Create results directory and path
path_results_data  <- paste0(path_prep_data,"/results")
if(dir.exists(path_results_data)==FALSE){
dir.create(path_results_data)
}
#### Load data ####
# Load MeSH concepts used in LLM mapping analysis
source_concept <-
read.csv(file=paste0(path_input_data,"/mesh-terms.csv"),
header = T, encoding = "UFT-8")
# Load UBERON and CL concepts used in LLM mapping analysis
target_concept <-
read.csv(file=paste0(path_input_data,"/uberon-terms.csv"),
header = T, encoding = "UFT-8")
# Load prepared in LLM mappings
# currently selects for vector results.
llm_mapping_paths <-
list.files(path=path_prep_data,
pattern="llm-prepared.csv", full.names = TRUE)
# Load Ground Truth mapping Data
evaluative_mappings <-
read.csv(file=paste0(path_eval_data,"/concept-mapping-evaluation-lookup-table-MGINDA.csv"),
header = T, encoding = "UFT-8")
# identify mappable concepts from initial set of subject concepts)
mappable_concepts <-
evaluative_mappings[evaluative_mappings$mappability=="Mappable",]$subject_label %>%
unique()
#### Create evaluation result mapping data frame ####
evaluation_results <-
data.frame(model = character(),
mappable_concepts = numeric(),
mapped_concepts = numeric(),
skipped_concepts = numeric(),
mapped_concepts_percent = numeric(),
hit = numeric(),
hit_as = numeric(),
hit_ct = numeric(),
miss = numeric(),
miss_as = numeric(),
miss_ct = numeric(),
hit_percent = numeric(),
hit_as_percent = numeric(),
hit_ct_percent = numeric(),
miss_percent = numeric(),
miss_as_percent = numeric(),
miss_ct_percent = numeric(),
mean_precision = numeric(),
mean_recall = numeric(),
f_score = numeric(),
beta = numeric(),
mean_reciprocal_rank = numeric(),
mean_reciprocal_rank_sd = numeric()
)
# Identify SSSOM mapping project
project <- paste((str_split(llm_mapping_paths[1],"/")[[1]][3]))
#### Concept Count Statitics ####
# MeSH Concept Counts
subject_concepts <- nrow(source_concept)
subject_concepts_as <- length(unique(evaluative_mappings[evaluative_mappings$mesh_concept_group=="Anatomical structure",]$subject_label))
subject_concepts_ct <- length(unique(evaluative_mappings[evaluative_mappings$mesh_concept_group=="Cell type",]$subject_label))
# Counts for mappable subject concepts
# Mapping Recalls (non-unique subject IDs)
mapping_recalls <- nrow(evaluative_mappings[evaluative_mappings$mappability=="Mappable",])
# Unique concepts
mappable_concepts <- length(unique(evaluative_mappings[evaluative_mappings$mappability=="Mappable",]$subject_id))
mappable_concepts_as <- length(unique(evaluative_mappings[evaluative_mappings$mappability=="Mappable" &
evaluative_mappings$mesh_concept_group=="Anatomical structure",]$subject_id))
mappable_concepts_ct <- length(unique(evaluative_mappings[evaluative_mappings$mappability=="Mappable" &
evaluative_mappings$mesh_concept_group=="Cell type",]$subject_id))
# UBERON and CL Concept Counts
target_concepts <- nrow(target_concept)
target_concepts_as <- nrow(target_concept[grepl("http://purl.obolibrary.org/obo/UBERON_",
target_concept$iri)==T,])
target_concepts_ct <- nrow(target_concept[grepl("http://purl.obolibrary.org/obo/CL_",
target_concept$iri)==T,])
#### Characterize unmappable MeSH Concepts ####
# by concept groups
tmp1 <-
evaluative_mappings %>%
filter(mappability=="Unmappable") %>%
ddply(.(mesh_concept_group), summarise,
concept_group = length(subject_id)) %>%
arrange(mesh_concept_group, desc(concept_group)) %>%
mutate(percent_subject_concept = round(concept_group/subject_concepts,3))
# by exclusion reason
tmp2 <-
evaluative_mappings %>%
filter(mappability=="Unmappable") %>%
ddply(.(mesh_concept_group, exclusion_reason), summarise,
concept_reason = length(subject_id))
# Combine both calculation dataframes.
mesh_unmappable_concept_statistics <-
join(tmp1, tmp2, by="mesh_concept_group") %>%
arrange(mesh_concept_group, desc(concept_group), desc(concept_reason)) %>%
mutate(percent_subject_concept_reasons = round(concept_reason/concept_group,2))
# Save results and clean up environmetn
write.csv(mesh_unmappable_concept_statistics,
file=paste0(path_results_data,"/mesh-unmappable-concept-statistics.csv"),
row.names = FALSE, fileEncoding = "UTF8")
rm(mesh_unmappable_concept_statistics, tmp1, tmp2)
#### Evaluate LLM Mapping Results ####
# Set F-score beta
beta = 2
# Evaluates mapped concepts, hit-miss stats, precision, recall, f-score, & MRR for LLM mapping results.
# Loop through each data file to calculate top line stats, hit-miss rates,
# f-scores, mrr and mac scores for each set of prepared model results.
i=1
for(i in 1:length(llm_mapping_paths)){
# Load data
data <- read.csv(file=llm_mapping_paths[i],
header = T, encoding = "UFT-8")
# Identify project model
model <- unique(data$model)
# Top line evaluation - subject concepts with and without mapping results (skipped).
results_subject_concepts_mapped <-
data %>%
filter(model_analyzed==TRUE) %>%
select(model,subject_id) %>%
distinct() %>%
ddply(.(model), summarise,
mappable_concepts = mappable_concepts,
mapped_concepts = length(subject_id),
skipped_concepts = mappable_concepts - length(subject_id),
mapped_concepts_percent = round(length(subject_id)/mappable_concepts, 3))
# Calculate hit and miss statistics for model results
results_hit_miss <-
data %>%
select(model, subject_id, hit_miss_concept) %>%
distinct() %>%
mutate(value=1) %>%
pivot_wider(id_cols = model,
names_from = hit_miss_concept,
values_from = value,
values_fn = length) %>%
mutate(hit_percent = round(Hit/mappable_concepts,2),
miss_percent = round(Miss/mappable_concepts,2)) %>%
select(model,Hit,Miss,hit_percent, miss_percent)
names(results_hit_miss)[2:3] <- c("hit","miss")
# Calculate hit and miss statistics for model results - Group level
results_hit_miss_groups <-
data %>%
select(model, subject_id, mesh_concept_group, hit_miss_concept) %>%
distinct() %>%
mutate(Value=1) %>%
pivot_wider(id_cols = model,
names_from = c(hit_miss_concept, mesh_concept_group),
values_from = Value,
values_fn = length) %>%
select(model,'Hit_Anatomical structure','Miss_Anatomical structure',
'Hit_Cell type', 'Miss_Cell type',)
names(results_hit_miss_groups)[2:5] <- c("hit_as","miss_as","hit_ct","miss_ct")
results_hit_miss_groups <-
results_hit_miss_groups %>%
mutate(hit_as_percent= round(hit_as/mappable_concepts_as,2),
miss_as_percent= round(miss_as/mappable_concepts_as,2),
hit_ct_percent= round(hit_ct/mappable_concepts_ct,2),
miss_ct_percent= round(miss_ct/mappable_concepts_ct,2))
# Precision at L
precision <-
data %>%
select(model, subject_id, accurate_mapping, concept_pair_rank) %>%
ddply(.(model, subject_id), summarise,
score_at_k = max(accurate_mapping),
precision_k = max(concept_pair_rank),
precision = max(accurate_mapping)/max(concept_pair_rank))
# Clean up precision for concepts llm skipped.
if(nrow(precision[is.na(precision$precision_k),])>0){
precision[is.na(precision$precision_k),]$precision_k <- 0
precision[is.na(precision$precision),]$precision <- 0
}
# Recall at L
recall <-
data %>%
select(model, subject_id, accurate_mapping, mapping_count) %>%
ddply(.(model, subject_id), summarise,
score_at_k = sum(accurate_mapping),
recall_k = max(mapping_count),
recall = sum(accurate_mapping)/max(mapping_count))
# Save model precision and recall calculations
mapping_scores_tmp <- join(precision, recall, by=c("model", "subject_id"))
write.csv(mapping_scores_tmp,
file=paste0(path_results_data,"/",model,
"-precision-recall-calculations.csv"),
row.names = FALSE)
# Mean Precision and Recall, calculate F-score at K
results_fscore <-
join(precision, recall, by=c("model", "subject_id")) %>%
select(model, precision, recall) %>%
ddply(.(model), summarise,
mean_precision = mean(precision, na.rm = T),
mean_recall = mean(recall, na.rm = T)) %>%
mutate(f_score=((1+beta^2)*mean_precision*mean_recall)/((beta^2*mean_precision)+mean_recall),
beta = beta)
rm(precision, recall, mapping_scores_tmp)
# Calculate Concept Level - Mean Reciprocal Rank (MRR)
# 1. Calculate reciprocal rank values for mapping records.
tmp0 <-
data %>%
mutate(reciprocal_rank = mapping_result_number/concept_pair_rank)
# 2. Calculate reciprocal rank for accurately mapped concepts.
tmp1 <-
tmp0 %>%
filter(mapping_result_number==1) %>%
select(model, subject_id, reciprocal_rank)
# 3. Calculate reciprocal rank for missed concepts.
tmp2 <-
tmp0 %>%
filter(hit_miss_concept=="Miss",
is.na(reciprocal_rank) == FALSE) %>%
ddply(.(model, subject_id), summarise,
reciprocal_rank = mean(reciprocal_rank, na.rm=TRUE))
# 4. Combine reciprocal rank calculations for each subject concept.
results_rr <-
union(tmp1,tmp2)
write.csv(results_rr,
file=paste0(path_results_data,"/",model,
"-concept-reciprocal-recall-calculations.csv"),
row.names = FALSE)
rm(tmp0, tmp1, tmp2)
# 5. Calculate mean reciprocal rank for the model
results_mrr <-
results_rr %>%
ddply(.(model), summarise,
mean_reciprocal_rank = mean(reciprocal_rank, na.rm=TRUE),
mean_reciprocal_rank_sd = sd(reciprocal_rank, na.rm=TRUE))
# Combine model evaluation statistics and organize variables.
evaluation_results_tmp <-
left_join(results_subject_concepts_mapped, results_hit_miss,
by="model") %>%
left_join(., results_hit_miss_groups, by="model") %>%
left_join(., results_fscore, by="model") %>%
left_join(., results_mrr, by="model") %>%
select(model, mappable_concepts, mapped_concepts,
skipped_concepts, mapped_concepts_percent,
hit, hit_as, hit_ct, miss, miss_as, miss_ct,
hit_percent, hit_as_percent, hit_ct_percent,
miss_percent, miss_as_percent, miss_ct_percent,
mean_precision, mean_recall, f_score, beta,
mean_reciprocal_rank, mean_reciprocal_rank_sd)
# Add model level statistics to data frame
evaluation_results <- rbind(evaluation_results, evaluation_results_tmp)
}
# save model evaluation results
write.csv(evaluation_results,
file=paste0(path_results_data,"/",project,
"-model-evaluation-results.csv"),
row.names = FALSE)
